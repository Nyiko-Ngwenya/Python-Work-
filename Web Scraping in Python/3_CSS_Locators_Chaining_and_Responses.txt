CSS Locator 

replaces / with >

dont need to have the first foward slash

Xpath = '/html/body/div'
CSS Locator = 'html>body>div'

replace the number of the element

Xpath = '//div/p[2]'
CSS Locator = 'div > p:nth-of-type(2)

# Create the XPath string equivalent to the CSS Locator 
xpath = '/div[@id="uid"]//span//h4'

# Create the CSS Locator string equivalent to the XPath
css_locator = 'div#uid > span h4'

from scrapy import Selector

# Create a selector from the html (of a secret website)
sel = Selector( text = html )

# Fill in the blank
css_locator = 'div.course-block > a'

# Print the number of selected elements.
how_many_elements( css_locator )

To get the attributes in CSS Locator 

Xpath = '/@attr-name
CSS = ::attr(attr)

EXAMPLE OF THIS 

Xpath = '//div[@id="uid"]/a/@href'
CSS = 'div.uid > a::attr(href)'

EXAMPLE OF SELECTING VARIABLES 


from scrapy import Selector

# Create a selector object from a secret website
sel = Selector( text=html )

# Select all hyperlinks of div elements belonging to class "course-block"
course_as = sel.css( 'div.course-block > a' )

# Selecting all href attributes chaining with css
hrefs_from_css = course_as.css( '::attr(href)' )

# Selecting all href attributes chaining with xpath
hrefs_from_xpath = course_as.xpath( './@href' )

EXAMPLE OF SELECTING TEXT FROM ONE GENERATION 

# Create an XPath string to the desired text.
xpath = '//p[@id="p3"]/text()'

# Create a CSS Locator string to the desired text.
css_locator = 'p#p3::text'

# Print the text from our selections
print_results( xpath, css_locator )

EXAMPLE OF SELECTING TEXT FROM ALL GENERATIONS AFTER


# Create an XPath string to the desired text.
xpath = '//p[@id="p3"]//text()'

# Create a CSS Locator string to the desired text.
css_locator = 'p#p3 ::text'

# Print the text from our selections
print_results( xpath, css_locator )

RESPONSE works the same as Selectors but provide more information like which website it got it from 

response.url // gets information on which uirl was visited

# Get the URL to the website loaded in response
this_url = response.url

# Get the title of the website loaded in response
this_title = response.css('html>head>title::text').extract_first()

# Print out our findings
print_url_title( this_url, this_title )


RESPONDING WITH SELECTORS

# Create a CSS Locator string to the desired hyperlink elements
css_locator = 'a.course-block__link'

# Select the hyperlink elements from response and sel
response_as = response.css(css_locator)
sel_as = sel.css(css_locator)

# Examine similarity
nr = len( response_as )
ns = len( sel_as )
for i in range( min(nr, ns, 2) ):
  print( "Element %d from response: %s" % (i+1, response_as[i]) )
  print( "Element %d from sel: %s" % (i+1, sel_as[i]) )
  print( "" )

EXAMPLE OF ACTUALLY SCRAPPING DATACAMP


# Create a SelectorList of the course titles
crs_title_els = response.css('h4::text')

# Extract the course titles 
crs_titles = crs_title_els.extract()

# Print out the course titles 
for el in crs_titles:
  print( ">>", el )


SCRAPPING WITH CHILDREN


# Calculate the number of children of the mystery element
how_many_kids = len( mystery.xpath( './*' ) )

# Print out the number
print( "The number of elements you selected was:", how_many_kids )