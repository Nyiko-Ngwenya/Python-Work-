kim jun gi
# Prepare a format string: time_format
time_format = '%Y-%m-%d %H:%M'

# Convert date_list into a datetime object: my_datetimes
my_datetimes = pd.to_datetime(date_list, format=time_format)  

# Construct a pandas Series using temperature_list and my_datetimes: time_series
time_series = pd.Series(temperature_list, index=my_datetimes)


EXAMPLE

# Extract the hour from 9pm to 10pm on '2010-10-11': ts1
ts1 = ts0.loc['2010-10-11 21:00:00':'2010-10-11 22:00:00']

# Extract '2010-07-04' from ts0: ts2
ts2 = ts0.loc['July 4th, 2010']

# Extract data from '2010-12-15' to '2010-12-31': ts3
ts3 = ts0.loc['12/15/2010':'12/31/2010']

# Reindex without fill method: ts3
ts3 = ts2.reindex(ts1.index)

# Reindex with fill method, using forward fill: ts4
ts4 = ts2.reindex(ts1.index, method= 'ffill')

RESAMPLING

Resampling must always to chained .

Downsaploing is going from daily to weekly
Upsampling is going from daily to hourly

to get daily samples // daily = df.resample('D').mean()  , daily.loc['2015-2-2']
to slice but only get certain col // sales.loc['day required','Units column']

sales.resample('D).sum().max()

T , min - minute
H - Hour
D - Daily
B - Business day
W - Weekly
M - Monthly
Q - Quarterly
A - Annualy

to resample using 2 weeks // sales.resample('2W').mean()  

# Downsample to 6 hour data and aggregate by mean: df1
df1 = df['Temperature'].resample('6H').mean()

# Downsample to daily data and count the number of data points: df2
df2 = df['Temperature'].resample('D').count()


EXAMPLE

# Extract temperature data for August: august
august = df.loc['2010 August', 'Temperature']

# Downsample to obtain only the daily highest temperatures in August: august_highs
august_highs = august.resample('D').max()

# Extract temperature data for February: february
february = df.loc['2010 February ', 'Temperature']

# Downsample to obtain the daily lowest temperatures in February: february_lows
february_lows = february.resample('D').min()


Rolling means (or moving averages) are generally used to smooth out short-term fluctuations in time series data and highlight long-term trends. 
For example, with a Series hourly_data, hourly_data.rolling(window=24).mean() would compute new values for each hourly point, based on a 24-hour window stretching out behind each point. 
The frequency of the output data is the same: it is still hourly. Such an operation is useful for smoothing time series data.


# Extract data from 2010-Aug-01 to 2010-Aug-15: unsmoothed
unsmoothed = df['Temperature']['August 1 2010':' August 15 2010']

# Apply a rolling mean with a 24 hour window: smoothed
smoothed = unsmoothed.rolling(window=24)

# Create a new DataFrame with columns smoothed and unsmoothed: august
august = pd.DataFrame({'smoothed':smoothed, 'unsmoothed':unsmoothed})

# Plot both smoothed and unsmoothed data using august.plot().
august.plot()
plt.show()


EXAMPLE

# Extract the August 2010 data: august
august = df['Temperature']['August 2010 ']

# Resample to daily data, aggregating by max: daily_highs
daily_highs = august.resample('D').max()

# Use a rolling 7-day window with method chaining to smooth the daily high temperatures in August
daily_highs_smoothed = daily_highs.rolling(window=7).mean()
print(daily_highs_smoothed)


SUBSTRING SETTING

search for string that contain the search string // sales['product'].str.contains('ware')